{
  "schema_version": "gatekeeper-artifact-v1.0",
  "timestamp": "2026-01-28T20:27:30.816987+00:00",
  "filepath": "/Users/frank/projects/claude-code-judge/artifact_writer.py",
  "mode": "repair-dry-run",
  "profile": "strict",
  "summary": {
    "initial_failure_count": 1,
    "final_failure_count": 1,
    "iterations_used": 1,
    "repair_confidence": 0.0,
    "improved": false,
    "fully_repaired": false
  },
  "failures": {
    "initial": [
      "Line 19: Function missing docstring"
    ],
    "final": [
      "Line 19: Function missing docstring"
    ]
  },
  "iterations": [
    {
      "iteration": 1,
      "failures_before": 1,
      "repairs_proposed": 1,
      "repairs": [
        {
          "line": 19,
          "old": "def write_repair_artifact(",
          "new": "def write_repair_artifact(",
          "reason": "Function already has a docstring on line 33",
          "category": "docstring",
          "blocking": false
        }
      ]
    }
  ],
  "diff": {
    "before": "\"\"\"\nArtifact Writer \u2014 Immutable Repair Evidence\n\nWrites repair artifacts for auditing, CI, and enterprise compliance.\nEvery repair produces a timestamped, validated, immutable JSON artifact.\n\"\"\"\n\nimport json\nfrom pathlib import Path\nfrom datetime import datetime, timezone\nfrom typing import Dict, List\nfrom schema_validator import validate_artifact_schema\n\n\nARTIFACT_DIR = Path(\".gatekeeper/artifacts\")\nARTIFACT_DIR.mkdir(parents=True, exist_ok=True)\n\n\ndef write_repair_artifact(\n    filepath: str,\n    profile: str,\n    mode: str,\n    initial_failures: List[str],\n    final_failures: List[str],\n    iterations_used: int,\n    repair_confidence: float,\n    history: List[Dict],\n    diff_before: str,\n    diff_after: str,\n    improved: bool\n) -> Path:\n    \"\"\"\n    Write an immutable, schema-validated repair artifact.\n    \n    Fails closed if schema validation fails.\n    \"\"\"\n    \n    timestamp = datetime.now(timezone.utc).isoformat()\n    \n    # Create safe filename from filepath\n    safe_name = filepath.replace(\"/\", \"_\").replace(\"\\\\\", \"_\")\n    timestamp_short = datetime.now(timezone.utc).strftime(\"%Y%m%d_%H%M%S\")\n    \n    artifact_filename = f\"{timestamp_short}_{safe_name}.json\"\n    artifact_path = ARTIFACT_DIR / artifact_filename\n    \n    # Build artifact\n    artifact = {\n        \"schema_version\": \"gatekeeper-artifact-v1.0\",\n        \"timestamp\": timestamp,\n        \"filepath\": filepath,\n        \"mode\": mode,\n        \"profile\": profile,\n        \"summary\": {\n            \"initial_failure_count\": len(initial_failures),\n            \"final_failure_count\": len(final_failures),\n            \"iterations_used\": iterations_used,\n            \"repair_confidence\": repair_confidence,\n            \"improved\": improved,\n            \"fully_repaired\": len(final_failures) == 0\n        },\n        \"failures\": {\n            \"initial\": initial_failures,\n            \"final\": final_failures\n        },\n        \"iterations\": history,\n        \"diff\": {\n            \"before\": diff_before,\n            \"after\": diff_after\n        },\n        \"metadata\": {\n            \"gatekeeper_version\": \"1.0.0\",\n            \"created_at\": timestamp\n        }\n    }\n    \n    # CRITICAL: Validate before writing\n    validate_artifact_schema(artifact)\n    \n    # Write atomically\n    artifact_path.write_text(json.dumps(artifact, indent=2))\n    \n    return artifact_path\n\n\ndef get_latest_artifacts(limit: int = 10) -> List[Path]:\n    \"\"\"Get most recent artifacts.\"\"\"\n    artifacts = sorted(ARTIFACT_DIR.glob(\"*.json\"), reverse=True)\n    return artifacts[:limit]\n\n\ndef load_artifact(artifact_path: Path) -> Dict:\n    \"\"\"Load and validate artifact from disk.\"\"\"\n    artifact = json.loads(artifact_path.read_text())\n    validate_artifact_schema(artifact)  # Validate on load too\n    return artifact\n\n\ndef generate_artifact_summary() -> Dict:\n    \"\"\"Generate summary statistics from all artifacts.\"\"\"\n    artifacts = list(ARTIFACT_DIR.glob(\"*.json\"))\n    \n    if not artifacts:\n        return {\n            \"total_repairs\": 0,\n            \"success_rate\": 0.0,\n            \"avg_confidence\": 0.0,\n            \"avg_iterations\": 0.0\n        }\n    \n    total = len(artifacts)\n    successful = 0\n    total_confidence = 0.0\n    total_iterations = 0\n    \n    for artifact_path in artifacts:\n        try:\n            artifact = load_artifact(artifact_path)\n            summary = artifact.get(\"summary\", {})\n            \n            if summary.get(\"fully_repaired\", False):\n                successful += 1\n            \n            total_confidence += summary.get(\"repair_confidence\", 0.0)\n            total_iterations += summary.get(\"iterations_used\", 0)\n        except Exception as e:\n            print(f\"WARNING: Could not load {artifact_path}: {e}\")\n            continue\n    \n    return {\n        \"total_repairs\": total,\n        \"successful_repairs\": successful,\n        \"success_rate\": round(successful / total, 3) if total > 0 else 0.0,\n        \"avg_confidence\": round(total_confidence / total, 3) if total > 0 else 0.0,\n        \"avg_iterations\": round(total_iterations / total, 2) if total > 0 else 0.0\n    }\n\n\nif __name__ == \"__main__\":\n    import sys\n    \n    if len(sys.argv) > 1 and sys.argv[1] == \"summary\":\n        summary = generate_artifact_summary()\n        print(json.dumps(summary, indent=2))\n    else:\n        print(\"Recent artifacts:\")\n        for artifact_path in get_latest_artifacts(5):\n            try:\n                artifact = load_artifact(artifact_path)\n                print(f\"\\n\u2705 {artifact_path.name}\")\n                print(f\"   File: {artifact['filepath']}\")\n                print(f\"   Confidence: {artifact['summary']['repair_confidence']}\")\n                print(f\"   Fully repaired: {artifact['summary']['fully_repaired']}\")\n            except Exception as e:\n                print(f\"\\n\u274c {artifact_path.name}\")\n                print(f\"   Error: {e}\")\n",
    "after": "\"\"\"\nArtifact Writer \u2014 Immutable Repair Evidence\n\nWrites repair artifacts for auditing, CI, and enterprise compliance.\nEvery repair produces a timestamped, validated, immutable JSON artifact.\n\"\"\"\n\nimport json\nfrom pathlib import Path\nfrom datetime import datetime, timezone\nfrom typing import Dict, List\nfrom schema_validator import validate_artifact_schema\n\n\nARTIFACT_DIR = Path(\".gatekeeper/artifacts\")\nARTIFACT_DIR.mkdir(parents=True, exist_ok=True)\n\n\ndef write_repair_artifact(\n    filepath: str,\n    profile: str,\n    mode: str,\n    initial_failures: List[str],\n    final_failures: List[str],\n    iterations_used: int,\n    repair_confidence: float,\n    history: List[Dict],\n    diff_before: str,\n    diff_after: str,\n    improved: bool\n) -> Path:\n    \"\"\"\n    Write an immutable, schema-validated repair artifact.\n    \n    Fails closed if schema validation fails.\n    \"\"\"\n    \n    timestamp = datetime.now(timezone.utc).isoformat()\n    \n    # Create safe filename from filepath\n    safe_name = filepath.replace(\"/\", \"_\").replace(\"\\\\\", \"_\")\n    timestamp_short = datetime.now(timezone.utc).strftime(\"%Y%m%d_%H%M%S\")\n    \n    artifact_filename = f\"{timestamp_short}_{safe_name}.json\"\n    artifact_path = ARTIFACT_DIR / artifact_filename\n    \n    # Build artifact\n    artifact = {\n        \"schema_version\": \"gatekeeper-artifact-v1.0\",\n        \"timestamp\": timestamp,\n        \"filepath\": filepath,\n        \"mode\": mode,\n        \"profile\": profile,\n        \"summary\": {\n            \"initial_failure_count\": len(initial_failures),\n            \"final_failure_count\": len(final_failures),\n            \"iterations_used\": iterations_used,\n            \"repair_confidence\": repair_confidence,\n            \"improved\": improved,\n            \"fully_repaired\": len(final_failures) == 0\n        },\n        \"failures\": {\n            \"initial\": initial_failures,\n            \"final\": final_failures\n        },\n        \"iterations\": history,\n        \"diff\": {\n            \"before\": diff_before,\n            \"after\": diff_after\n        },\n        \"metadata\": {\n            \"gatekeeper_version\": \"1.0.0\",\n            \"created_at\": timestamp\n        }\n    }\n    \n    # CRITICAL: Validate before writing\n    validate_artifact_schema(artifact)\n    \n    # Write atomically\n    artifact_path.write_text(json.dumps(artifact, indent=2))\n    \n    return artifact_path\n\n\ndef get_latest_artifacts(limit: int = 10) -> List[Path]:\n    \"\"\"Get most recent artifacts.\"\"\"\n    artifacts = sorted(ARTIFACT_DIR.glob(\"*.json\"), reverse=True)\n    return artifacts[:limit]\n\n\ndef load_artifact(artifact_path: Path) -> Dict:\n    \"\"\"Load and validate artifact from disk.\"\"\"\n    artifact = json.loads(artifact_path.read_text())\n    validate_artifact_schema(artifact)  # Validate on load too\n    return artifact\n\n\ndef generate_artifact_summary() -> Dict:\n    \"\"\"Generate summary statistics from all artifacts.\"\"\"\n    artifacts = list(ARTIFACT_DIR.glob(\"*.json\"))\n    \n    if not artifacts:\n        return {\n            \"total_repairs\": 0,\n            \"success_rate\": 0.0,\n            \"avg_confidence\": 0.0,\n            \"avg_iterations\": 0.0\n        }\n    \n    total = len(artifacts)\n    successful = 0\n    total_confidence = 0.0\n    total_iterations = 0\n    \n    for artifact_path in artifacts:\n        try:\n            artifact = load_artifact(artifact_path)\n            summary = artifact.get(\"summary\", {})\n            \n            if summary.get(\"fully_repaired\", False):\n                successful += 1\n            \n            total_confidence += summary.get(\"repair_confidence\", 0.0)\n            total_iterations += summary.get(\"iterations_used\", 0)\n        except Exception as e:\n            print(f\"WARNING: Could not load {artifact_path}: {e}\")\n            continue\n    \n    return {\n        \"total_repairs\": total,\n        \"successful_repairs\": successful,\n        \"success_rate\": round(successful / total, 3) if total > 0 else 0.0,\n        \"avg_confidence\": round(total_confidence / total, 3) if total > 0 else 0.0,\n        \"avg_iterations\": round(total_iterations / total, 2) if total > 0 else 0.0\n    }\n\n\nif __name__ == \"__main__\":\n    import sys\n    \n    if len(sys.argv) > 1 and sys.argv[1] == \"summary\":\n        summary = generate_artifact_summary()\n        print(json.dumps(summary, indent=2))\n    else:\n        print(\"Recent artifacts:\")\n        for artifact_path in get_latest_artifacts(5):\n            try:\n                artifact = load_artifact(artifact_path)\n                print(f\"\\n\u2705 {artifact_path.name}\")\n                print(f\"   File: {artifact['filepath']}\")\n                print(f\"   Confidence: {artifact['summary']['repair_confidence']}\")\n                print(f\"   Fully repaired: {artifact['summary']['fully_repaired']}\")\n            except Exception as e:\n                print(f\"\\n\u274c {artifact_path.name}\")\n                print(f\"   Error: {e}\")\n"
  },
  "metadata": {
    "gatekeeper_version": "1.0.0",
    "created_at": "2026-01-28T20:27:30.816987+00:00"
  }
}